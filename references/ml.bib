@ARTICLE{Pejo2019-jr,
  title    = "Together or Alone: The Price of Privacy in Collaborative Learning",
  author   = "Pej{\'o}, Bal{\'a}zs and Tang, Qiang and Bicz{\'o}k, Gergely",
  abstract = "Machine learning algorithms have reached mainstream status and
              are widely deployed in many applications. The accuracy of such
              algorithms depends significantly on the size of the underlying
              training dataset; in reality a small or medium sized organization
              often does not have the necessary data to train a reasonably
              accurate model. For such organizations, a realistic solution is
              to train their machine learning models based on their joint
              dataset (which is a union of the individual ones). Unfortunately,
              privacy concerns prevent them from straightforwardly doing so.
              While a number of privacy-preserving solutions exist for
              collaborating organizations to securely aggregate the parameters
              in the process of training the models, we are not aware of any
              work that provides a rational framework for the participants to
              precisely balance the privacy loss and accuracy gain in their
              collaboration. In this paper, by focusing on a two-player
              setting, we model the collaborative training process as a
              two-player game where each player aims to achieve higher accuracy
              while preserving the privacy of its own dataset. We introduce the
              notion of Price of Privacy , a novel approach for measuring the
              impact of privacy protection on the accuracy in the proposed
              framework. Furthermore, we develop a game-theoretical model for
              different player types, and then either find or prove the
              existence of a Nash Equilibrium with regard to the strength of
              privacy protection for each player. Using recommendation systems
              as our main use case, we demonstrate how two players can make
              practical use of the proposed theoretical framework, including
              setting up the parameters and approximating the non-trivial Nash
              Equilibrium.",
  journal  = "Proceedings on Privacy Enhancing Technologies",
  volume   =  2019,
  number   =  2,
  pages    = "47--65",
  year     =  2019,
  url      = "http://dx.doi.org/10.2478/popets-2019-0019",
  keywords = "accepted; game theory; machine learning; privacy; received;
              recommendation systems; revised",
  arxivid  = "1712.00270",
  doi      = "10.2478/popets-2019-0019"
}

@ARTICLE{Hartford2016-gp,
  title    = "Deep learning for predicting human strategic behavior",
  author   = "Hartford, Jason and Wright, James R and Leyton-Brown, Kevin",
  abstract = "Predicting the behavior of human participants in strategic
              settings is an important problem in many domains. Most existing
              work either assumes that participants are perfectly rational, or
              attempts to directly model each participant's cognitive processes
              based on insights from cognitive psychology and experimental
              economics. In this work, we present an alternative, a deep
              learning approach that automatically performs cognitive modeling
              without relying on such expert knowledge. We introduce a novel
              architecture that allows a single network to generalize across
              different input and output dimensions by using matrix units
              rather than scalar units, and show that its performance
              significantly outperforms that of the previous state of the art,
              which relies on expert-constructed features.",
  journal  = "Adv. Neural Inf. Process. Syst.",
  number   = "Nips",
  pages    = "2432--2440",
  year     =  2016,
  issn     = "1049-5258"
}

@ARTICLE{Toulis2016-gg,
  title    = "Long-term causal effects via behavioral game theory",
  author   = "Toulis, Panagiotis and Parkes, David C",
  abstract = "Planned experiments are the gold standard in reliably comparing
              the causal effect of switching from a baseline policy to a new
              policy. One critical shortcoming of classical experimental
              methods, however, is that they typically do not take into account
              the dynamic nature of response to policy changes. For instance,
              in an experiment where we seek to understand the effects of a new
              ad pricing policy on auction revenue, agents may adapt their
              bidding in response to the experimental pricing changes. Thus,
              causal effects of the new pricing policy after such adaptation
              period, the long-term causal effects, are not captured by the
              classical methodology even though they clearly are more
              indicative of the value of the new policy. Here, we formalize a
              framework to define and estimate long-term causal effects of
              policy changes in multiagent economies. Central to our approach
              is behavioral game theory, which we leverage to formulate the
              ignorability assumptions that are necessary for causal inference.
              Under such assumptions we estimate long-term causal effects
              through a latent space approach, where a behavioral model of how
              agents act conditional on their latent behaviors is combined with
              a temporal model of how behaviors evolve over time.",
  journal  = "Adv. Neural Inf. Process. Syst.",
  number   = "Nips",
  pages    = "2612--2620",
  year     =  2016,
  url      = "http://arxiv.org/abs/1501.02315",
  issn     = "1049-5258",
  arxivid  = "1501.02315"
}

@MISC{Agrawal1981-dd,
  title        = "When machine learning meets {AI} and game theory",
  author       = "Agrawal, Anurag and Jaiswal, Deepak",
  abstract     = "---We study the problem of development of intelligent machine
                  learning applications to exploit the problems of adap-tation
                  that arise in multi-agent systems, for
                  expected-long-term-profit maximization. We present two
                  results. First, we propose a learning algorithm for the
                  Iterated Prisoners Dilemma (IPD) problem. Using numerical
                  analysis we show that it performs strictly better than the
                  tit-for-tat algorithm and many other adaptive and
                  non-adaptive strategies. Second, we study the same problem
                  from the aspect of zero-sum games. We discuss how AI and
                  Machine Learning techniques work closely to give our agent a
                  'mind-reading' capability.",
  year         =  1981,
  url          = "http://cs229.stanford.edu/proj2012/AgrawalJaiswal-WhenMachineLearningMeetsAIandGameTheory.pdf",
  howpublished = "\url{http://cs229.stanford.edu/proj2012/AgrawalJaiswal-WhenMachineLearningMeetsAIandGameTheory.pdf}"
}

@ARTICLE{Goodfellow2016-mh,
  title         = "{NIPS} 2016 Tutorial: Generative Adversarial Networks",
  author        = "Goodfellow, Ian",
  abstract      = "This report summarizes the tutorial presented by the author
                   at NIPS 2016 on generative adversarial networks (GANs). The
                   tutorial describes: (1) Why generative modeling is a topic
                   worth studying, (2) how generative models work, and how GANs
                   compare to other generative models, (3) the details of how
                   GANs work, (4) research frontiers in GANs, and (5)
                   state-of-the-art image models that combine GANs with other
                   methods. Finally, the tutorial contains three exercises for
                   readers to complete, and the solutions to these exercises.",
  month         =  dec,
  year          =  2016,
  url           = "http://arxiv.org/abs/1701.00160",
  archivePrefix = "arXiv",
  eprint        = "1701.00160",
  primaryClass  = "cs.LG",
  arxivid       = "1701.00160"
}

@ARTICLE{Mirza2014-xs,
  title         = "Conditional Generative Adversarial Nets",
  author        = "Mirza, Mehdi and Osindero, Simon",
  abstract      = "Generative Adversarial Nets [8] were recently introduced as
                   a novel way to train generative models. In this work we
                   introduce the conditional version of generative adversarial
                   nets, which can be constructed by simply feeding the data,
                   y, we wish to condition on to both the generator and
                   discriminator. We show that this model can generate MNIST
                   digits conditioned on class labels. We also illustrate how
                   this model could be used to learn a multi-modal model, and
                   provide preliminary examples of an application to image
                   tagging in which we demonstrate how this approach can
                   generate descriptive tags which are not part of training
                   labels.",
  month         =  nov,
  year          =  2014,
  url           = "http://arxiv.org/abs/1411.1784",
  archivePrefix = "arXiv",
  eprint        = "1411.1784",
  primaryClass  = "cs.LG",
  arxivid       = "1411.1784"
}

@ARTICLE{Goodfellow2014-kv,
  title         = "Generative Adversarial Networks",
  author        = "Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi
                   and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and
                   Courville, Aaron and Bengio, Yoshua",
  abstract      = "We propose a new framework for estimating generative models
                   via an adversarial process, in which we simultaneously train
                   two models: a generative model G that captures the data
                   distribution, and a discriminative model D that estimates
                   the probability that a sample came from the training data
                   rather than G. The training procedure for G is to maximize
                   the probability of D making a mistake. This framework
                   corresponds to a minimax two-player game. In the space of
                   arbitrary functions G and D, a unique solution exists, with
                   G recovering the training data distribution and D equal to
                   1/2 everywhere. In the case where G and D are defined by
                   multilayer perceptrons, the entire system can be trained
                   with backpropagation. There is no need for any Markov chains
                   or unrolled approximate inference networks during either
                   training or generation of samples. Experiments demonstrate
                   the potential of the framework through qualitative and
                   quantitative evaluation of the generated samples.",
  month         =  jun,
  year          =  2014,
  url           = "http://arxiv.org/abs/1406.2661",
  archivePrefix = "arXiv",
  eprint        = "1406.2661",
  primaryClass  = "stat.ML",
  arxivid       = "1406.2661"
}

@ARTICLE{Gorban2012-eh,
  title         = "General H-theorem and entropies that violate the second law",
  author        = "Gorban, Alexander N",
  abstract      = "$H$-theorem states that the entropy production is
                   nonnegative and, therefore, the entropy of a closed system
                   should monotonically change in time. In information
                   processing, the entropy production is positive for random
                   transformation of signals (the information processing
                   lemma). Originally, the $H$-theorem and the information
                   processing lemma were proved for the classical
                   Boltzmann-Gibbs-Shannon entropy and for the correspondent
                   divergence (the relative entropy). Many new entropies and
                   divergences have been proposed during last decades and for
                   all of them the $H$-theorem is needed. This note proposes a
                   simple and general criterion to check whether the
                   $H$-theorem is valid for a convex divergence $H$ and
                   demonstrates that some of the popular divergences obey no
                   $H$-theorem. We consider systems with $n$ states $A_i$ that
                   obey first order kinetics (master equation). A convex
                   function $H$ is a Lyapunov function for all master equations
                   with given equilibrium if and only if its conditional minima
                   properly describe the equilibria of pair transitions $A_i
                   \rightleftharpoons A_j$. This theorem does not depend on the
                   principle of detailed balance and is valid for general
                   Markov kinetics. Elementary analysis of pair equilibria
                   demonstrates that the popular Bregman divergences like
                   Euclidean distance or Itakura-Saito distance in the space of
                   distribution cannot be the universal Lyapunov functions for
                   the first-order kinetics and can increase in Markov
                   processes. Therefore, they violate the second law and the
                   information processing lemma. In particular, for these
                   measures of information (divergences) random manipulation
                   with data may add information to data. The main results are
                   extended to nonlinear generalized mass action law kinetic
                   equations. In Appendix, a new family of the universal
                   Lyapunov functions for the generalized mass action law
                   kinetics is described.",
  month         =  dec,
  year          =  2012,
  url           = "http://arxiv.org/abs/1212.6767",
  archivePrefix = "arXiv",
  eprint        = "1212.6767",
  primaryClass  = "cond-mat.stat-mech",
  arxivid       = "1212.6767"
}

@ARTICLE{Nowozin2016-ri,
  title         = "{f-GAN}: Training Generative Neural Samplers using
                   Variational Divergence Minimization",
  author        = "Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota",
  abstract      = "Generative neural samplers are probabilistic models that
                   implement sampling using feedforward neural networks: they
                   take a random input vector and produce a sample from a
                   probability distribution defined by the network weights.
                   These models are expressive and allow efficient computation
                   of samples and derivatives, but cannot be used for computing
                   likelihoods or for marginalization. The
                   generative-adversarial training method allows to train such
                   models through the use of an auxiliary discriminative neural
                   network. We show that the generative-adversarial approach is
                   a special case of an existing more general variational
                   divergence estimation approach. We show that any
                   f-divergence can be used for training generative neural
                   samplers. We discuss the benefits of various choices of
                   divergence functions on training complexity and the quality
                   of the obtained generative models.",
  month         =  jun,
  year          =  2016,
  url           = "http://arxiv.org/abs/1606.00709",
  archivePrefix = "arXiv",
  eprint        = "1606.00709",
  primaryClass  = "stat.ML",
  arxivid       = "1606.00709"
}

@ARTICLE{Chen2016-jg,
  title         = "{InfoGAN}: Interpretable Representation Learning by
                   Information Maximizing Generative Adversarial Nets",
  author        = "Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman,
                   John and Sutskever, Ilya and Abbeel, Pieter",
  abstract      = "This paper describes InfoGAN, an information-theoretic
                   extension to the Generative Adversarial Network that is able
                   to learn disentangled representations in a completely
                   unsupervised manner. InfoGAN is a generative adversarial
                   network that also maximizes the mutual information between a
                   small subset of the latent variables and the observation. We
                   derive a lower bound to the mutual information objective
                   that can be optimized efficiently, and show that our
                   training procedure can be interpreted as a variation of the
                   Wake-Sleep algorithm. Specifically, InfoGAN successfully
                   disentangles writing styles from digit shapes on the MNIST
                   dataset, pose from lighting of 3D rendered images, and
                   background digits from the central digit on the SVHN
                   dataset. It also discovers visual concepts that include hair
                   styles, presence/absence of eyeglasses, and emotions on the
                   CelebA face dataset. Experiments show that InfoGAN learns
                   interpretable representations that are competitive with
                   representations learned by existing fully supervised
                   methods.",
  month         =  jun,
  year          =  2016,
  url           = "http://arxiv.org/abs/1606.03657",
  archivePrefix = "arXiv",
  eprint        = "1606.03657",
  primaryClass  = "cs.LG",
  arxivid       = "1606.03657"
}

@ARTICLE{Radford2015-lz,
  title         = "Unsupervised Representation Learning with Deep Convolutional
                   Generative Adversarial Networks",
  author        = "Radford, Alec and Metz, Luke and Chintala, Soumith",
  abstract      = "In recent years, supervised learning with convolutional
                   networks (CNNs) has seen huge adoption in computer vision
                   applications. Comparatively, unsupervised learning with CNNs
                   has received less attention. In this work we hope to help
                   bridge the gap between the success of CNNs for supervised
                   learning and unsupervised learning. We introduce a class of
                   CNNs called deep convolutional generative adversarial
                   networks (DCGANs), that have certain architectural
                   constraints, and demonstrate that they are a strong
                   candidate for unsupervised learning. Training on various
                   image datasets, we show convincing evidence that our deep
                   convolutional adversarial pair learns a hierarchy of
                   representations from object parts to scenes in both the
                   generator and discriminator. Additionally, we use the
                   learned features for novel tasks - demonstrating their
                   applicability as general image representations.",
  month         =  nov,
  year          =  2015,
  url           = "http://arxiv.org/abs/1511.06434",
  archivePrefix = "arXiv",
  eprint        = "1511.06434",
  primaryClass  = "cs.LG",
  arxivid       = "1511.06434"
}
