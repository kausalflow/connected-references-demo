@ARTICLE{Liu2020-yh,
  title         = "Self-supervised Learning: Generative or Contrastive",
  author        = "Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Wang, Zhaoyu
                   and Mian, Li and Zhang, Jing and Tang, Jie",
  abstract      = "Deep supervised learning has achieved great success in the
                   last decade. However, its deficiencies of dependence on
                   manual labels and vulnerability to attacks have driven
                   people to explore a better solution. As an alternative,
                   self-supervised learning attracts many researchers for its
                   soaring performance on representation learning in the last
                   several years. Self-supervised representation learning
                   leverages input data itself as supervision and benefits
                   almost all types of downstream tasks. In this survey, we
                   take a look into new self-supervised learning methods for
                   representation in computer vision, natural language
                   processing, and graph learning. We comprehensively review
                   the existing empirical methods and summarize them into three
                   main categories according to their objectives: generative,
                   contrastive, and generative-contrastive (adversarial). We
                   further investigate related theoretical analysis work to
                   provide deeper thoughts on how self-supervised learning
                   works. Finally, we briefly discuss open problems and future
                   directions for self-supervised learning. An outline slide
                   for the survey is provided.",
  month         =  jun,
  year          =  2020,
  url           = "http://arxiv.org/abs/2006.08218",
  archivePrefix = "arXiv",
  eprint        = "2006.08218",
  primaryClass  = "cs.LG",
  arxivid       = "2006.08218"
}

@ARTICLE{Nowozin2016-ri,
  title         = "{f-GAN}: Training Generative Neural Samplers using
                   Variational Divergence Minimization",
  author        = "Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota",
  abstract      = "Generative neural samplers are probabilistic models that
                   implement sampling using feedforward neural networks: they
                   take a random input vector and produce a sample from a
                   probability distribution defined by the network weights.
                   These models are expressive and allow efficient computation
                   of samples and derivatives, but cannot be used for computing
                   likelihoods or for marginalization. The
                   generative-adversarial training method allows to train such
                   models through the use of an auxiliary discriminative neural
                   network. We show that the generative-adversarial approach is
                   a special case of an existing more general variational
                   divergence estimation approach. We show that any
                   f-divergence can be used for training generative neural
                   samplers. We discuss the benefits of various choices of
                   divergence functions on training complexity and the quality
                   of the obtained generative models.",
  month         =  jun,
  year          =  2016,
  url           = "http://arxiv.org/abs/1606.00709",
  archivePrefix = "arXiv",
  eprint        = "1606.00709",
  primaryClass  = "stat.ML",
  arxivid       = "1606.00709"
}

@ARTICLE{Chen2016-jg,
  title         = "{InfoGAN}: Interpretable Representation Learning by
                   Information Maximizing Generative Adversarial Nets",
  author        = "Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman,
                   John and Sutskever, Ilya and Abbeel, Pieter",
  abstract      = "This paper describes InfoGAN, an information-theoretic
                   extension to the Generative Adversarial Network that is able
                   to learn disentangled representations in a completely
                   unsupervised manner. InfoGAN is a generative adversarial
                   network that also maximizes the mutual information between a
                   small subset of the latent variables and the observation. We
                   derive a lower bound to the mutual information objective
                   that can be optimized efficiently, and show that our
                   training procedure can be interpreted as a variation of the
                   Wake-Sleep algorithm. Specifically, InfoGAN successfully
                   disentangles writing styles from digit shapes on the MNIST
                   dataset, pose from lighting of 3D rendered images, and
                   background digits from the central digit on the SVHN
                   dataset. It also discovers visual concepts that include hair
                   styles, presence/absence of eyeglasses, and emotions on the
                   CelebA face dataset. Experiments show that InfoGAN learns
                   interpretable representations that are competitive with
                   representations learned by existing fully supervised
                   methods.",
  month         =  jun,
  year          =  2016,
  url           = "http://arxiv.org/abs/1606.03657",
  archivePrefix = "arXiv",
  eprint        = "1606.03657",
  primaryClass  = "cs.LG",
  arxivid       = "1606.03657"
}

@ARTICLE{Devon_Hjelm2018-da,
  title         = "Learning deep representations by mutual information
                   estimation and maximization",
  author        = "Devon Hjelm, R and Fedorov, Alex and Lavoie-Marchildon,
                   Samuel and Grewal, Karan and Bachman, Phil and Trischler,
                   Adam and Bengio, Yoshua",
  abstract      = "In this work, we perform unsupervised learning of
                   representations by maximizing mutual information between an
                   input and the output of a deep neural network encoder.
                   Importantly, we show that structure matters: incorporating
                   knowledge about locality of the input to the objective can
                   greatly influence a representation's suitability for
                   downstream tasks. We further control characteristics of the
                   representation by matching to a prior distribution
                   adversarially. Our method, which we call Deep InfoMax (DIM),
                   outperforms a number of popular unsupervised learning
                   methods and competes with fully-supervised learning on
                   several classification tasks. DIM opens new avenues for
                   unsupervised learning of representations and is an important
                   step towards flexible formulations of
                   representation-learning objectives for specific end-goals.",
  month         =  aug,
  year          =  2018,
  url           = "http://arxiv.org/abs/1808.06670",
  archivePrefix = "arXiv",
  eprint        = "1808.06670",
  primaryClass  = "stat.ML",
  arxivid       = "1808.06670"
}

@ARTICLE{Van_den_Oord2018-tz,
  title         = "Representation Learning with Contrastive Predictive Coding",
  author        = "van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol",
  abstract      = "While supervised learning has enabled great progress in many
                   applications, unsupervised learning has not seen such
                   widespread adoption, and remains an important and
                   challenging endeavor for artificial intelligence. In this
                   work, we propose a universal unsupervised learning approach
                   to extract useful representations from high-dimensional
                   data, which we call Contrastive Predictive Coding. The key
                   insight of our model is to learn such representations by
                   predicting the future in latent space by using powerful
                   autoregressive models. We use a probabilistic contrastive
                   loss which induces the latent space to capture information
                   that is maximally useful to predict future samples. It also
                   makes the model tractable by using negative sampling. While
                   most prior work has focused on evaluating representations
                   for a particular modality, we demonstrate that our approach
                   is able to learn useful representations achieving strong
                   performance on four distinct domains: speech, images, text
                   and reinforcement learning in 3D environments.",
  month         =  jul,
  year          =  2018,
  url           = "http://arxiv.org/abs/1807.03748",
  archivePrefix = "arXiv",
  eprint        = "1807.03748",
  primaryClass  = "cs.LG",
  arxivid       = "1807.03748"
}
